{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Evaluation\n",
    "## Table of Contents\n",
    "1. [Model Selection](#model-selection)\n",
    "2. [Feature Engineering](#feature-engineering)\n",
    "3. [Hyperparameter Tuning](#hyperparameter-tuning)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Evaluation Metrics](#evaluation-metrics)\n",
    "6. [Comparative Analysis](#comparative-analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# set logging level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Params\n",
    "SEED = 123\n",
    "IMG_SIZE = (224, 224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "I pondered the use of different established models for Image Classification, because I was shure that I could not create a better Neural Net from scratch. I read about different NNs and landed first on ResNet50 because of an article about monochromatic image classification (I can no longer find it, and did not save it ). I changed it to the ResNet 152V2 because of the better performance of the second version of the ResNets and the 152 version because I thought I could try to unfreeze more of the top layers if necessary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Because I had the dataset I used, I was not able to do a lot of feature engineering, that was not already incorporated in the dataset.I just needed to scale the size and pixel values to appropriate values for the ResNet NN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "\n",
    "train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "    '../1_DatasetCharacteristics/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_data = keras.preprocessing.image_dataset_from_directory(\n",
    "    '../1_DatasetCharacteristics/train/',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    ")\n",
    "\n",
    "# normalization layer and scale for ResNet152V2\n",
    "norm_layer = keras.layers.Rescaling(1/127.5, offset=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "The most Hyperparameter Tuning I did, was on the batch size, epochs, learning rate, retrain layers. I also played with the Dropout layer rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # I tried a lot of batch sizes, but always came back to 32, because of no significant advantage\n",
    "EPOCHS = 10 # more epochs definitely were just overfitting\n",
    "LEARNING_RATE = 0.01 # two stage training, for the basemodel I reduced by one magnitude\n",
    "RETRAIN_LAYER = 35 # less yield worse results, and more I felt like it was diminishing returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement the final model(s) you've selected based on the above steps.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization layer and scale for ResNet152V2\n",
    "norm_layer = keras.layers.Rescaling(1/127.5, offset=-1)\n",
    "\n",
    "# define and use basemodel ResNet 152V2\n",
    "base_model = keras.applications.ResNet152V2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "# freeze the basemodel for it to run in inference mode\n",
    "base_model.trainable = False\n",
    "\n",
    "input = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = input\n",
    "x = keras.applications.resnet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# add global average pooling layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add dropout layer\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# define output layer\n",
    "outputs = keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "# define model input and output\n",
    "model = keras.Model(input, outputs)\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(train_data, epochs=EPOCHS, validation_data=test_data, verbose=1)\n",
    "\n",
    "#unfreeze parts of the basemodel\n",
    "for layer in base_model.layers[-RETRAIN_LAYER:]:\n",
    "    if not isinstance(layer, keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "        \n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE/10)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(train_data, epochs=EPOCHS, validation_data=test_data, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "The only really relevant metric is accuracy, so it is the only one to track.\n",
    "\n",
    "Loss is important to check for over fitting on the validation side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save history\n",
    "np.save('history.npy', history.history)\n",
    "print('History saved')\n",
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# save plot\n",
    "plt.savefig('accuracy.png')\n",
    "# compare predictions with actual labels\n",
    "predictions = model.predict(test_data)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "actual = np.concatenate([y for x, y in test_data], axis=0)\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = np.mean(predictions == actual)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis\n",
    "\n",
    "Comparing just the accuracy of the baseline and the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
